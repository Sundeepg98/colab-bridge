#!/usr/bin/env python3
"""
Test the hybrid processor specifically
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv

load_dotenv()
sys.path.insert(0, str(Path(__file__).parent))

from colab_integration.bridge import ClaudeColabBridge

def test_hybrid():
    print("ğŸ§ª Testing Hybrid Processor")
    print("=" * 50)
    
    bridge = ClaudeColabBridge()
    bridge.initialize()
    
    # Create a test that will show clear output
    test_code = '''
print("ğŸ‰ SUCCESS! Hybrid processor is working!")
print("=" * 50)

import datetime
import platform
import sys

print(f"â° Processed at: {datetime.datetime.now()}")
print(f"ğŸ Python: {platform.python_version()}")
print(f"ğŸ–¥ï¸  System: {platform.system()}")

# Test some computation
import numpy as np
arr = np.random.rand(1000)
mean_val = np.mean(arr)
std_val = np.std(arr)

print(f"ğŸ”¢ Random array mean: {mean_val:.4f}")
print(f"ğŸ“Š Random array std: {std_val:.4f}")

# Test GPU if available
try:
    import torch
    if torch.cuda.is_available():
        device = torch.cuda.get_device_name(0)
        memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        print(f"ğŸš€ GPU: {device}")
        print(f"ğŸ’¾ Memory: {memory:.1f} GB")
    else:
        print("ğŸ’» CPU only (no GPU)")
except ImportError:
    print("ğŸ“¦ PyTorch not available")

print("=" * 50)
print("âœ… Test completed successfully!")
'''
    
    print("ğŸ“¤ Sending test to hybrid processor...")
    print("\nğŸ“‹ Expected result if processor is running:")
    print("- Request gets processed automatically")
    print("- Response appears in Drive folder")
    print("- Shows Python/system info and computations")
    
    try:
        result = bridge.execute_code(test_code, timeout=30)
        
        if result.get('status') == 'success':
            print("\nğŸ‰ HYBRID PROCESSOR IS RUNNING!")
            print("ğŸ“‹ Output:")
            print("-" * 50)
            print(result.get('output'))
            print("-" * 50)
        else:
            print(f"\nğŸ“‹ Request queued (ID: {result.get('request_id', 'pending')})")
            print("\nğŸ”— To start the hybrid processor:")
            print("   https://colab.research.google.com/drive/1XhtEroHqX5Y8hetP-xCN_FMF-Ea81tAA")
            print("\nğŸ“ It will:")
            print("   1. Auto-run when you open it")
            print("   2. Process this test request")
            print("   3. Show debug cells for monitoring")
            
    except Exception as e:
        print(f"\nâ±ï¸ Request created but timed out: {e}")
        print("\nğŸ”— Start the hybrid processor:")
        print("   https://colab.research.google.com/drive/1XhtEroHqX5Y8hetP-xCN_FMF-Ea81tAA")

if __name__ == "__main__":
    test_hybrid()